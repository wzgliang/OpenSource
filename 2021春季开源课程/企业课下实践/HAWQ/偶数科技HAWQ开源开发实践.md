# 偶数科技开源开发实践

## 1. 开发任务介绍

Apache HAWQ是面向企业用户的先进大规模分布式分析型数据库，完整支持SQL规范并提供极其优秀的大数据分析性能表现。其采用了存储与计算分离技术架构，除了吸收了MPP的优点，还具有弹性执行，支持混合工作负载和高扩展性等特性，提供了PB级数据交互式查询能力。HAWQ的开发始于2011年，在基于Greenplum和Postgres多年积累的基础上，成功开发出了适配Hadoop的企业级SQL分析引擎。2018年8月15日，HAWQ正式毕业并成为Apache顶级项目。

通过参加Apache HAWQ的线下实践课程，同学们可以在巩固系统级编程技术的基础上进一步学习大数据处理的相关技术和Apache基金会项目的开发模式。本次课程实践选题分为五大类，同学们可以在和企业导师沟通后组队或者独立选择其中一项。

这些选题分别专注于数据库内核新功能研发；软件开发实践中持续集成支持；国产化适配和软件可移植性提高；可重复的软件性能基准测试；项目历史问题的修复和测试补充。每类选题在贯彻ASF开发模式的前提下分别关注不同的软件开发技术，引导同学们逐步融入Apache HAWQ开发社区，体会开源软件开发的协作模式。

- 添加新的Apache HAWQ外部表格式支持

  > Apache HAWQ当下通过可插拔存储框架支持访问HDFS，但是仅支持ORC格式。为了进一步增加HAWQ访问外部HDFS数据源的功能支持，需要进一步提供不同的常用数据格式的支持。本实践可以利用Apache Arrow项目，需要大量使用C/C++编程。

  - TEXT/CSV
  - ORC
  - Parquet

- DevOps集成

  > *持续集成*是一种软件开发实践，即团队开发成员经常集成他们的工作，通常每个成员每天至少集成一次，也就意味着每天可能会发生多次集成。每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。
  >
  > 本实践分类依托于Github Action，需要调试各种配置文件和运维脚本。

  - GitHub Action
  - 格式化工具和lint检查
  - 代码覆盖率报告
  - 不同平台的打包工作

- 可移植性适配

  > Apache HAWQ当下仅支持x86_64架构，迁移到国产化平台上需要适配更多的处理器体系结构。
  >
  > 本实践分类需要对不同工具链调试，需要熟悉系统级编程知识（编译链接运行）。

  - ARM
  - MIPS

- 可重复的基准测试评测

  > 一般来说，大数据具有3V特性，即Volume（海量）、Velocity（高速）和Variety（多样）。如何客观地比较不同数据管理系统，即大数据测试基准的选择，成为一个重要的研究课题。
  >
  > 本类实践需要编写可重复的完整测试步骤，方便新用户进行基准性能测试。相应的操作步骤和参考结果需要更新到HAWQ的文档中。

  - TPC-H
  - TPC-DS
  - SSB

- 功能修复和测试的补充

  > 针对HAWQ已存在问题进行修复。

  - 测试补充
  - 技术文档的修改和编写
  - 升级工具
  - 元数据版本一致性检查工具
    - 升级测试

## 2. 任务培养目标

- 熟悉大数据基础软件的原理和使用
- 熟悉Apache社区开发流程
- 熟悉和实践持续集成
- 进行大数据基础软件(Apache HAWQ)的内核开发

## 3. 拟培养人数

实践总人数为6~9人，每2~3人分配一个企业导师，根据选题限制协调组队或者独立开发。

## 4. 企业导师介绍

⌈偶数科技⌋是一家领先的AI和大数据软件提供商，致力于为全球各行业客户提供AI和新一代企业级数据仓库产品，公司的愿景和使命是 “让人类只为兴趣而工作”。 目前⌈偶数科技⌋已经获得⌈红杉中国⌋、⌈红点中国⌋和⌈金山云⌋的三轮投资。 

公司核心产品为新一代云原生数据仓库OushuDB、人工智能系统LittleBoy和数据云平台Lava。OushuDB是新一代云原生数据仓库，也是一个可以原生运行在容器云平台中的并行数据仓库引擎。 LittleBoy是您身边的"人工智能科学家"，帮助你轻松解决一切和人工智能相关的难题。 Lava是一款针对企业用户推出的数据云平台，提供企业用户快速完成数字化转型所需的大数据服务。核心团队来自EMC/Pivotal，IBM，Oracle，Google， Microsoft等著名AI和大数据企业，拥有领先的AI和大数据处理技术，研究成果发表在国际顶级会议中，并拥有多项国际专利。

- 常雷

  > Apache HAWQ数据库顶级项目创始人
  >
  > - 偶数科技创始人
  > - 前EMC高级研究员，组建Greenplum和HAWQ中国数据库团队
  > - 国内外顶级数据管理期刊和会议（如SIGMOD等）发表数篇论文，并拥有多项美国专利
  > - 中国计算机学会数据库专委，中国大数据产业生态联盟专家和中国人工智能百人专家 
  > - 快公司”中国商业最具创意人物100”
  > - 2008年博士毕业于北京大学计算机系

- 陶征霖

  > 偶数科技首席架构师
  >
  > - 负责数据库架构、优化器、执行器等核心模块的研发。
  > - Apache Committer，项目管理委员会PMC成员
  > - 曾服务于Oracle和EMC数据库组，负责数据库存储等核心模块的研发
  > - 毕业于浙江大学计算机系

- 万炽洋

  > 偶数科技核心研发工程师
  >
  > - 本次Apache HAWQ开发实践的内容组织人员
  > - Apache HAWQ committer，有多年大数据基础软件内核开发经验
  > - 负责高性能数据库执行器和云原生存储等核心组件的开发工作
  > - 毕业于北京大学计算机系


- 汪思学

  > 偶数科技核心研发工程师
  >
  > - 负责数据库资源管理器和虚拟计算集群等数据库等核心组件的开发
  > - 毕业于北京大学计算机系
  > - 曾获NOI银牌


## 5. 课程计划

> 包括时间安排3.8--5.31可延长至六月底、课程具体内容、阶段性培养目标。

重规范和原则，轻原理和技术。

1. Apache HAWQ的编译安装部署以及基本使用

   > 成功在机器上安装运行HAWQ并运行简单语句。
   >
   > 动作比较快的同学可以尝试进行编译启动。

   1. macOS brew install
   2. Ubuntu
   3. Docker

2. Apache HAWQ开发工具的使用

   - IDE配置，代码索引的使用
   - 测试运行
   - 相关的DevOps流程

3. 项目任务布置

   - Apache HAWQ概念知识巩固
   - 提交流程和开发技巧

4. 开发过程答疑

5. 根据实践情况进行调整

6. 根据实践情况进行调整

7. 中期开发实践检查和验收

   - 需要有有效的开发改动

8. 根据实践情况进行调整

9. 开发实践的初步点评和汇总交流

   - 开发内容的初步展示，需要形成初步的PR

10. 根据实践情况进行调整

11. 根据实践情况进行调整

12. 总结交流，点评各个任务

## 6. 评分标准

> 考核方式
>
> 评分细则

考核方式分为硬性考核指标和企业导师主观评分两部分，下面是初定的评分分数值比例。

- 硬性考核指标 **70%**

  - 合格 **30%**

    > 每个步骤递进**10%**。
    >
    > 1. 成功编译启动运行调试Apache HAWQ
    > 2. 对文档或者内核代码进行修改
    > 3. 形成一个有效的提交

  - 良好 **20%**

    > 独立完成一系列提交

  - 优秀 **10%**

    > 实现一个完整的功能

- 企业导师主观评分 **30%**

  > 由企业导师参考学校课程规定和同学表现进行调配。

## 7. 课程资源

> 企业可以提供的资源

- https://cwiki.apache.org/confluence/display/HAWQ
- http://hawq.apache.org/docs/userguide/latest/index.html

- 数据库系统概念第6版

  > 基本概念参考

- 大数据浪潮之巅

  > 书的内容偏向新闻读物
  >
  > 可以根据书的目录去搜索相关的论文

- https://github.com/pingcap/awesome-database-learning